{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.feature_selection import RFECV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV, learning_curve, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart_failure_clinical_records_dataset.csv', delimiter=',', header=0)\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DEATH_EVENT\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.savefig('class_dristribution.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def types_loading(df):\n",
    "    global X, y, feature_names, X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    df['sex'] = df['sex'].astype(\"category\")\n",
    "    df['smoking'] = df['smoking'].astype(\"category\")\n",
    "    df['high_blood_pressure'] = df['high_blood_pressure'].astype(\"category\")\n",
    "    df['diabetes'] = df['diabetes'].astype(\"category\")\n",
    "    df['anaemia'] = df['anaemia'].astype(\"category\")\n",
    "    \n",
    "    # Removal of time variable due to date leak\n",
    "    df = df.drop(['time'], axis=1)  \n",
    "    \n",
    "    cor = df.corr() \n",
    "    corr_target = abs(cor[\"DEATH_EVENT\"])\n",
    "    \n",
    "    # Removal of low-correlated variables\n",
    "    relevant_features = corr_target[corr_target>0.07]\n",
    "    df =  df[relevant_features.index.tolist()]\n",
    "\n",
    "    X = df.drop(['DEATH_EVENT'], axis=1)  \n",
    "    y = df['DEATH_EVENT']\n",
    "\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost + RFECV + RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_rfecv(scoring_metric, imbalanced_data):\n",
    "    global best_params, grid_search, xgb_clf_best, removed_features, rfecv, X_train_rfe, explainer, shap_values, X_test_rfe, cm\n",
    "\n",
    "    xgb_clf = XGBClassifier(scoring_metric=scoring_metric, enable_categorical=True, objective=\"binary:logistic\")\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    rfecv = RFECV(estimator=xgb_clf, cv=cv,step=1, scoring=\"f1\", n_jobs=-1)\n",
    "    rfecv.fit(X_train, Y_train)\n",
    "    \n",
    "    X_train_rfe = rfecv.transform(X_train)\n",
    "    X_test_rfe = rfecv.transform(X_test)\n",
    "    \n",
    "    selected_features = [feature for feature, selected in zip(feature_names, rfecv.support_) if selected]\n",
    "    print(\"Selected features:\", selected_features)\n",
    "    \n",
    "    param_grid = {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': randint(3, 9),\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'subsample': uniform(0.6, 0.4),\n",
    "        'colsample_bytree': uniform(0.6, 0.4),\n",
    "        'alpha': uniform(0, 1),\n",
    "        'lambda': uniform(0, 1),\n",
    "        'min_child_weight': randint(1, 10),\n",
    "        'gamma': uniform(0, 1)\n",
    "    }\n",
    "\n",
    "    param_grid['scoring_metric'] = [scoring_metric]\n",
    "    \n",
    "    if imbalanced_data:\n",
    "        scale_pos_weight = float(Y_train.value_counts()[0]) / Y_train.value_counts()[1]\n",
    "        param_grid['scale_pos_weight'] = [scale_pos_weight]\n",
    "\n",
    "    randomized_search = RandomizedSearchCV(estimator=xgb_clf, param_distributions=param_grid, scoring=\"accuracy\", n_iter=50, cv=cv)\n",
    "    randomized_search.fit(X_train, Y_train)\n",
    "    best_params_rfe = randomized_search.best_params_\n",
    "    \n",
    "    # Best parameters based on 20 repetitions\n",
    "    # best_params_rfe = {'alpha': np.float64(0.3384698508856418), 'colsample_bytree': np.float64(0.7005590471231655), 'gamma': np.float64(0.14738669475440902), 'lambda': np.float64(0.5690549590459144), 'learning_rate': np.float64(0.023898523910037408), 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 82, 'scale_pos_weight': np.float64(2.3661971830985915), 'scoring_metric': make_scorer(f1_score, response_method='predict'), 'subsample': np.float64(0.9506076926900313)}\n",
    "    \n",
    "    print(best_params_rfe)\n",
    "\n",
    "    xgb_clf_best = XGBClassifier(**best_params_rfe,enable_categorical=True, objective=\"binary:logistic\")\n",
    "    xgb_clf_best.fit(X_train_rfe, Y_train)\n",
    "\n",
    "    explainer = shap.TreeExplainer(xgb_clf_best)\n",
    "    shap_values = explainer(np.array(X_test_rfe))\n",
    "\n",
    "    y_pred_rfe = xgb_clf_best.predict(X_test_rfe)\n",
    "    print(\"Accuracy:\", accuracy_score(Y_test, y_pred_rfe))\n",
    "    print(\"Precision:\", precision_score(Y_test, y_pred_rfe))\n",
    "    print(\"Recall:\", recall_score(Y_test, y_pred_rfe))\n",
    "    print(\"F1:\", f1_score(Y_test, y_pred_rfe))\n",
    "    \n",
    "    cm = confusion_matrix(Y_test, y_pred_rfe)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    false_positive_rate = fp / (fp + tn)\n",
    "    false_negative_rate = fn / (fn + tp)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(f\"False Positive Rate: {false_positive_rate:.2f}\")\n",
    "    print(f\"False Negative Rate: {false_negative_rate:.2f}\")\n",
    "\n",
    "    removed_features2 = [feature_names[i] for i in range(len(feature_names)) if not rfecv.support_[i]]  \n",
    "    print(f'Removed features: {removed_features2}')\n",
    "    \n",
    "    return xgb_clf_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve_chart():\n",
    "    global scoring_metric, train_sizes, train_scores, test_scores\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        xgb_clf_best, X_train_rfe, Y_train, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10), scoring=scoring_metric\n",
    "    )\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='r')\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='g')\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')\n",
    "\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Training examples')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('cv-score.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance():\n",
    "    selected_features = [feature for feature, selected in zip(feature_names, rfecv.support_) if selected]  \n",
    "    selected_importances = xgb_clf_best.feature_importances_\n",
    "\n",
    "    importance_df = pd.DataFrame({'Feature': selected_features, 'Importance': selected_importances})  \n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)  \n",
    "      \n",
    "    plt.figure(figsize=(12, 8))  \n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'])  \n",
    "    plt.xlabel('Importance')  \n",
    "    plt.ylabel('Feature')  \n",
    "    plt.title('Feature Importance from XGBoost')  \n",
    "    plt.gca().invert_yaxis()  \n",
    "    plt.savefig('feature_importance.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_chart():\n",
    "    selected_features = [feature for feature, selected in zip(feature_names, rfecv.support_) if selected]  \n",
    "    shap.summary_plot(shap_values, X_test_rfe, feature_names=selected_features, show=False)  \n",
    "\n",
    "    plt.savefig('shap.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_chart():\n",
    "    plt.figure(figsize=(8, 6))  \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['True','False'], yticklabels=['True','False'])  \n",
    "    plt.xlabel('Predicted')  \n",
    "    plt.ylabel('Actual')  \n",
    "    plt.title('Confusion Matrix') \n",
    "    plt.savefig('confusion.jpg') \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_data = 1\n",
    "scoring_metric = make_scorer(f1_score)\n",
    "\n",
    "print(scoring_metric)\n",
    "\n",
    "types_loading(df)\n",
    "\n",
    "final_model = xgb_rfecv(scoring_metric, imbalanced_data)\n",
    "\n",
    "learning_curve_chart()\n",
    "feature_importance()   \n",
    "shap_chart()\n",
    "cm_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"xgb_reg.pkl\"\n",
    "\n",
    "pickle.dump(final_model, open(file_name, \"wb\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
